{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d95a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt # importing matplotlib\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "import seaborn as sns\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f246ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stanting timming process\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488f5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the main directory\n",
    "main_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e012e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subfolder_name = [f.name for f in os.scandir(main_directory) if f.is_dir()]\n",
    "subfolder_with_path = [\"\" for i in range(4)]\n",
    "subfolder_with_path[0] = main_directory + '/'+'01Activity_files'\n",
    "subfolder_with_path[1] = main_directory + '/'+'02Volume_files'\n",
    "subfolder_with_path[2] = main_directory + '/'+'03Volume_in_tissue_files'\n",
    "subfolder_with_path[3] = main_directory + '/'+'zzz_input_and_reference_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83625283",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Importing information from \"samples overview\", \"intensisties template\" and \"brain allen map\"\n",
    "###############################################################################################\n",
    "\n",
    "# Changing directory to the \"zzz_input_and_reference_files\" folder\n",
    "os.chdir(subfolder_with_path[-1])\n",
    "\n",
    "\n",
    "# Reading \"sample_overview.csv\" file\n",
    "samples_overview = pd.read_csv(\"sample_overview.csv\", \n",
    "                               dtype={\"MOUSE\": \"string\",\"SAMPLE\": int,\n",
    "                                      \"FILES_HD\": int,\"FILES_BOX\": int,\n",
    "                                      \"hemisphere\": \"string\",\"MARKER\": \"string\",\n",
    "                                      \"TX_GROUP\": \"string\", \n",
    "                                      \"GENDER\":\"string\", \n",
    "                                      \"CONTEXT\":\"string\"})\n",
    "\n",
    "# Reading \"gubra_intensities_template.csv\" file\n",
    "gubra_intensities_template = pd.read_csv(\"gubra_intensities_template_fixed_080922.csv\",\n",
    "                                   dtype={\"IDPath\": \"string\", \n",
    "                                          \"LabelID\": int, \n",
    "                                          \"raw\": \"string\", \n",
    "                                          \"LabelAbrv\": \"string\"})\n",
    "# Reading \"brain_allen_map.csv\" file\n",
    "brain_gubra_map = pd.read_csv(\"brain_gubra_map_fixed_080822.csv\", \n",
    "                               dtype={\"IDPath\": \"string\", \"LabelAbrv\": \"string\",\n",
    "                                      \"raw\": \"string\",\"allen_1\": \"string\",\n",
    "                                      \"allen_2\": \"string\",\"allen_3\": \"string\",\n",
    "                                      \"allen_4\": \"string\",\"allen_5\": \"string\",\n",
    "                                      \"allen_6\": \"string\",\"allen_7\": \"string\",\n",
    "                                      \"fine\": \"string\",\"medium\": \"string\",\n",
    "                                      \"coarse\": \"string\", \"all\":\"string\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c4188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2723b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving drugs and markers' names from the \"sample_overview\" file\n",
    "\n",
    "drugs = samples_overview['TX_GROUP'].unique()\n",
    "markers = samples_overview['marker'].unique()\n",
    "\n",
    "d = 0\n",
    "m = 0\n",
    "counters_names = []\n",
    "while (m < len(markers)):\n",
    "    while (d < len(drugs)):\n",
    "        counters_names.append(drugs[d] + '_' + markers[m])\n",
    "        d += 1\n",
    "    m += 1\n",
    "    d = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6547ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"02Volume_files\" folder\n",
    "os.chdir(subfolder_with_path[1])\n",
    "\n",
    "#Counting number of files on \"02Volume_files\" folder\n",
    "list = os.listdir(subfolder_with_path[1]) \n",
    "number_files = len(list)\n",
    "number_volume_files = number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f3f7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using and timing  a loop to process all files and populate the main data-frame\n",
    "\n",
    "volume_data = [] #This array will contain df as elements\n",
    "\n",
    "i = 0\n",
    "while i < number_files:\n",
    "\n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "    \n",
    "    file = list[i]\n",
    "    # Saving sample's number\n",
    "    filename_segmented = file.split('_')\n",
    "    sample = filename_segmented[1]\n",
    "\n",
    "\n",
    "    # Reading file's data\n",
    "    header = [\"PIXEL_COUNT\"]\n",
    "    pixels_count_volume = pd.read_csv(file, names = header)\n",
    "    pixels_count_volume.insert(0, column = 'INTENSITY', value = range(0, len(pixels_count_volume))) \n",
    "\n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(pixels_count_volume, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    volume_label_name = 'VOLUME'\n",
    "    output = output.rename(columns = {'PIXEL_COUNT':volume_label_name})\n",
    "    output['VOLUME'] = output['VOLUME'].div(1000000).round(7)\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "   \n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    volume_data.append(output)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframe\n",
    "volume_data = pd.concat(volume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ffaf238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31a5014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"03Volume_in_tissue_files\" folder\n",
    "os.chdir(subfolder_with_path[2])\n",
    "\n",
    "#Counting number of files on \"03Volume_in_tissue_files\" folder\n",
    "list = os.listdir(subfolder_with_path[2]) \n",
    "number_files = len(list)\n",
    "number_volintissue_files = number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5d028ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using and timing  a loop to process all files and populate the main data-frame\n",
    "\n",
    "volume_intissue_data = [] #This array will contain df as elements\n",
    "\n",
    "#Staring counters\n",
    "\n",
    "i = 0 #General loop counter\n",
    "\n",
    "\n",
    "#Zeroing the counters \n",
    "counters = np.zeros(len(counters_names))\n",
    "\n",
    "#Creating counters array to contain sample's names as elements\n",
    "counters_samples = [[] for j in range(len(counters_names))]\n",
    "\n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "\n",
    "while i < number_files:\n",
    "\n",
    "\n",
    "    file = list[i]\n",
    "    # Saving sample's number \n",
    "    filename_segmented = file.split('_')\n",
    "    sample = filename_segmented[1]\n",
    "\n",
    "    # Reading file's data\n",
    "    header = [\"PIXEL_COUNT\"]\n",
    "    pixels_count_volume = pd.read_csv(file, names = header)\n",
    "    pixels_count_volume.insert(0, column = 'INTENSITY', value = range(0, len(pixels_count_volume))) \n",
    "\n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(pixels_count_volume, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    volume_label_name = 'VOLUME_IN_TISSUE'\n",
    "    output = output.rename(columns = {'PIXEL_COUNT':volume_label_name})\n",
    "    output['VOLUME_IN_TISSUE'] = output['VOLUME_IN_TISSUE'].div(1000000).round(6)\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Merging activity and sample overview data-frames\n",
    "    output= pd.merge(output,samples_overview[['SAMPLE',\n",
    "                                             'hemisphere','marker',\n",
    "                                             'TX_GROUP']],on='SAMPLE',how='inner')\n",
    "    \n",
    "    #Adding a column with the sample's nickname\n",
    "\n",
    "    counters_index = counters_names.index(output['TX_GROUP'].iloc[0] + '_' + output['marker'].iloc[0])\n",
    "    if output['SAMPLE'].iloc[0] not in counters_samples[counters_index]:\n",
    "        counters[counters_index] += 1\n",
    "        counters_samples[counters_index].append(output['SAMPLE'].iloc[0])\n",
    "        nickname = 'v' + output['TX_GROUP'].iloc[0] + '_' + str(int(counters[counters_index]))\n",
    "\n",
    "    nickname_column = np.empty(len(output))    \n",
    "    output['nickname'] = nickname_column\n",
    "    output['nickname'] = nickname\n",
    "    \n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    volume_intissue_data.append(output)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframeo\n",
    "volume_intissue_data = pd.concat(volume_intissue_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad7ff9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating volume ratio\n",
    "volumes_data = pd.merge(volume_intissue_data,volume_data[['raw','VOLUME','SAMPLE']],on=('raw','SAMPLE'),how='left')\n",
    "volumes_data['volumes_ratio'] = volumes_data['VOLUME_IN_TISSUE'] / volumes_data['VOLUME'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd0ba663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDPath</th>\n",
       "      <th>LabelID</th>\n",
       "      <th>raw</th>\n",
       "      <th>LabelAbrv</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>VOLUME_IN_TISSUE</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>hemisphere</th>\n",
       "      <th>marker</th>\n",
       "      <th>TX_GROUP</th>\n",
       "      <th>nickname</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>volumes_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/997/8/343/1065/354/370/653/</td>\n",
       "      <td>20653</td>\n",
       "      <td>Abducens_nucleus</td>\n",
       "      <td>VI</td>\n",
       "      <td>L</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>Psilocybin</td>\n",
       "      <td>vPsilocybin_1</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/997/8/343/1065/354/370/576/</td>\n",
       "      <td>20576</td>\n",
       "      <td>Accessory_facial_motor_nucleus</td>\n",
       "      <td>ACVII</td>\n",
       "      <td>L</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>Psilocybin</td>\n",
       "      <td>vPsilocybin_1</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/997/8/567/688/695/698/151/188/</td>\n",
       "      <td>20188</td>\n",
       "      <td>Accessory_olfactory_bulb_glomerular_layer</td>\n",
       "      <td>AOBgl</td>\n",
       "      <td>L</td>\n",
       "      <td>0.034308</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>Psilocybin</td>\n",
       "      <td>vPsilocybin_1</td>\n",
       "      <td>0.035119</td>\n",
       "      <td>0.976907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/997/8/567/688/695/698/151/196/</td>\n",
       "      <td>20196</td>\n",
       "      <td>Accessory_olfactory_bulb_granular_layer</td>\n",
       "      <td>AOBgr</td>\n",
       "      <td>L</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>Psilocybin</td>\n",
       "      <td>vPsilocybin_1</td>\n",
       "      <td>0.053358</td>\n",
       "      <td>0.227670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/997/8/567/688/695/698/151/204/</td>\n",
       "      <td>20204</td>\n",
       "      <td>Accessory_olfactory_bulb_mitral_layer</td>\n",
       "      <td>AOBmi</td>\n",
       "      <td>L</td>\n",
       "      <td>0.035592</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>Psilocybin</td>\n",
       "      <td>vPsilocybin_1</td>\n",
       "      <td>0.063514</td>\n",
       "      <td>0.560380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8920</th>\n",
       "      <td>/997/8/567/688/695/315/677/1058/</td>\n",
       "      <td>21058</td>\n",
       "      <td>Visceral_area_layer_5</td>\n",
       "      <td>VISC5</td>\n",
       "      <td>L</td>\n",
       "      <td>0.229714</td>\n",
       "      <td>40.0</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>Saline</td>\n",
       "      <td>vSaline_9</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8921</th>\n",
       "      <td>/997/8/567/688/695/315/677/857/</td>\n",
       "      <td>20857</td>\n",
       "      <td>Visceral_area_layer_6a</td>\n",
       "      <td>VISC6a</td>\n",
       "      <td>L</td>\n",
       "      <td>0.195096</td>\n",
       "      <td>40.0</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>Saline</td>\n",
       "      <td>vSaline_9</td>\n",
       "      <td>0.097548</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8922</th>\n",
       "      <td>/997/8/567/688/695/315/677/849/</td>\n",
       "      <td>20849</td>\n",
       "      <td>Visceral_area_layer_6b</td>\n",
       "      <td>VISC6b</td>\n",
       "      <td>L</td>\n",
       "      <td>0.010972</td>\n",
       "      <td>40.0</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>Saline</td>\n",
       "      <td>vSaline_9</td>\n",
       "      <td>0.005486</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8923</th>\n",
       "      <td>/997/1009/967/949/</td>\n",
       "      <td>20949</td>\n",
       "      <td>vomeronasal_nerve</td>\n",
       "      <td>von</td>\n",
       "      <td>L</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>40.0</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>Saline</td>\n",
       "      <td>vSaline_9</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>1.221043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8924</th>\n",
       "      <td>/997/8/343/1129/1097/290/797/</td>\n",
       "      <td>20797</td>\n",
       "      <td>Zona_incerta</td>\n",
       "      <td>ZI</td>\n",
       "      <td>L</td>\n",
       "      <td>0.729832</td>\n",
       "      <td>40.0</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>Saline</td>\n",
       "      <td>vSaline_9</td>\n",
       "      <td>0.364916</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8925 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                IDPath  LabelID  \\\n",
       "0         /997/8/343/1065/354/370/653/    20653   \n",
       "1         /997/8/343/1065/354/370/576/    20576   \n",
       "2      /997/8/567/688/695/698/151/188/    20188   \n",
       "3      /997/8/567/688/695/698/151/196/    20196   \n",
       "4      /997/8/567/688/695/698/151/204/    20204   \n",
       "...                                ...      ...   \n",
       "8920  /997/8/567/688/695/315/677/1058/    21058   \n",
       "8921   /997/8/567/688/695/315/677/857/    20857   \n",
       "8922   /997/8/567/688/695/315/677/849/    20849   \n",
       "8923                /997/1009/967/949/    20949   \n",
       "8924     /997/8/343/1129/1097/290/797/    20797   \n",
       "\n",
       "                                            raw LabelAbrv Unnamed: 4  \\\n",
       "0                              Abducens_nucleus        VI          L   \n",
       "1                Accessory_facial_motor_nucleus     ACVII          L   \n",
       "2     Accessory_olfactory_bulb_glomerular_layer     AOBgl          L   \n",
       "3       Accessory_olfactory_bulb_granular_layer     AOBgr          L   \n",
       "4         Accessory_olfactory_bulb_mitral_layer     AOBmi          L   \n",
       "...                                         ...       ...        ...   \n",
       "8920                      Visceral_area_layer_5     VISC5          L   \n",
       "8921                     Visceral_area_layer_6a    VISC6a          L   \n",
       "8922                     Visceral_area_layer_6b    VISC6b          L   \n",
       "8923                          vomeronasal_nerve       von          L   \n",
       "8924                               Zona_incerta        ZI          L   \n",
       "\n",
       "      VOLUME_IN_TISSUE  SAMPLE hemisphere marker    TX_GROUP       nickname  \\\n",
       "0             0.007952     2.0       left   cfos  Psilocybin  vPsilocybin_1   \n",
       "1             0.000822     2.0       left   cfos  Psilocybin  vPsilocybin_1   \n",
       "2             0.034308     2.0       left   cfos  Psilocybin  vPsilocybin_1   \n",
       "3             0.012148     2.0       left   cfos  Psilocybin  vPsilocybin_1   \n",
       "4             0.035592     2.0       left   cfos  Psilocybin  vPsilocybin_1   \n",
       "...                ...     ...        ...    ...         ...            ...   \n",
       "8920          0.229714    40.0       left   cfos      Saline      vSaline_9   \n",
       "8921          0.195096    40.0       left   cfos      Saline      vSaline_9   \n",
       "8922          0.010972    40.0       left   cfos      Saline      vSaline_9   \n",
       "8923          0.008402    40.0       left   cfos      Saline      vSaline_9   \n",
       "8924          0.729832    40.0       left   cfos      Saline      vSaline_9   \n",
       "\n",
       "        VOLUME  volumes_ratio  \n",
       "0     0.007952       1.000000  \n",
       "1     0.000822       1.000000  \n",
       "2     0.035119       0.976907  \n",
       "3     0.053358       0.227670  \n",
       "4     0.063514       0.560380  \n",
       "...        ...            ...  \n",
       "8920  0.114857       2.000000  \n",
       "8921  0.097548       2.000000  \n",
       "8922  0.005486       2.000000  \n",
       "8923  0.006881       1.221043  \n",
       "8924  0.364916       2.000000  \n",
       "\n",
       "[8925 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volumes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a8b4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting dataframe to have nicknames as columns\n",
    "pivoted_volumes_data = pd.pivot_table(volumes_data, values='VOLUME_IN_TISSUE', \n",
    "                                       index=['raw'],columns=['nickname'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9643587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"01Activity_files\" folder\n",
    "os.chdir(subfolder_with_path[0])\n",
    "\n",
    "#Counting number of files on \"01Activity_files\" folder\n",
    "list = os.listdir(subfolder_with_path[0]) \n",
    "number_files = len(list)\n",
    "number_activity_files = number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fed307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using and timing  a loop to process all files and populate the main data-frame\n",
    "\n",
    "activity_data = [] #This array will contain df as elements\n",
    "\n",
    "# Extractiing pixel information\n",
    "pixel_data = [] #This array will contain df as elements\n",
    "\n",
    "#Starting counters\n",
    "\n",
    "i = 0 #General loop counter\n",
    "\n",
    "#Zeroing the counters \n",
    "counters = np.zeros(len(counters_names))\n",
    "\n",
    "#Creating counters array to contain sample's names as elements\n",
    "counters_samples = [[] for j in range(len(counters_names))]\n",
    "\n",
    "\n",
    "    ##############################################\n",
    "    # Innitiates loop to process each file\n",
    "    ##############################################\n",
    "\n",
    "\n",
    "while i < number_files:\n",
    "\n",
    "    # Working with each file at a time\n",
    "    file = list[i]\n",
    "    \n",
    "    # Saving sample's number\n",
    "    filename_segmented = file.split('_')\n",
    "    sample = filename_segmented[1]\n",
    "\n",
    "    # Reading file's data\n",
    "    regions_count_activity_fracc = pd.read_csv(file,low_memory=False)\n",
    "    #Cleanning row that have the srting \"PIXEL_COUNT\" instead of values\n",
    "    regions_count_activity_fracc = regions_count_activity_fracc[regions_count_activity_fracc.PIXEL_COUNT != \"PIXEL_COUNT\"] \n",
    "    #Filtering rows where the pixel counts is repeated more than 10 times\n",
    "    regions_count_activity_fracc =  regions_count_activity_fracc.groupby('PIXEL_COUNT').filter(lambda x : len(x)>10)\n",
    "    \n",
    "    # Storing pixel counts of each file\n",
    "    pixel_count = regions_count_activity_fracc[[\"PIXEL_COUNT\"]]\n",
    "    pixel_count = pixel_count.astype(float)\n",
    "\n",
    "    # Adding-up regions' fracctions\n",
    "    regions_fracc_1 = regions_count_activity_fracc[[\"INTENSITY_1\", \"INTENSITY_1_PERC\"]]\n",
    "    regions_fracc_2 = regions_count_activity_fracc[[\"INTENSITY_2\", \"INTENSITY_2_PERC\"]]\n",
    "    regions_fracc_3 = regions_count_activity_fracc[[\"INTENSITY_3\", \"INTENSITY_3_PERC\"]]\n",
    "    regions_fracc_1 = regions_fracc_1.rename(columns={\"INTENSITY_1\": \"INTENSITY\",\"INTENSITY_1_PERC\" : \"COUNTS\"})\n",
    "    regions_fracc_2 = regions_fracc_2.rename(columns={\"INTENSITY_2\": \"INTENSITY\",\"INTENSITY_2_PERC\" : \"COUNTS\"})\n",
    "    regions_fracc_3 = regions_fracc_3.rename(columns={\"INTENSITY_3\": \"INTENSITY\",\"INTENSITY_3_PERC\" : \"COUNTS\"})\n",
    "    total_region_activity = regions_fracc_1.append(regions_fracc_2, \n",
    "                                                   ignore_index=True).append(regions_fracc_3, ignore_index=True)\n",
    "    total_region_activity[\"COUNTS\"] = total_region_activity[\"COUNTS\"].astype(float)\n",
    "    total_region_activity = total_region_activity.groupby(['INTENSITY']).agg('sum').reset_index()\n",
    "#     total_region_activity[\"COUNTS\"] = total_region_activity[\"COUNTS\"].round(0)\n",
    "    total_region_activity[\"INTENSITY\"] = total_region_activity[\"INTENSITY\"].astype(int)\n",
    "        \n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(total_region_activity, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    activity_label_name = 'ACTIVITY'\n",
    "    output = output.rename(columns = {'COUNTS':activity_label_name})\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Merging activity and sample overview data-frames\n",
    "    output= pd.merge(output,samples_overview[['SAMPLE',\n",
    "                                             'hemisphere','marker',\n",
    "                                             'TX_GROUP']],on='SAMPLE',how='inner')\n",
    "    \n",
    "    \n",
    "    #Adding a column with the sample's nickname\n",
    "\n",
    "    counters_index = counters_names.index(output['TX_GROUP'].iloc[0] + '_' + output['marker'].iloc[0])\n",
    "    if output['SAMPLE'].iloc[0] not in counters_samples[counters_index]:\n",
    "        counters[counters_index] += 1\n",
    "        counters_samples[counters_index].append(output['SAMPLE'].iloc[0])\n",
    "        nickname = output['TX_GROUP'].iloc[0] + '_' + str(int(counters[counters_index]))\n",
    "\n",
    "    nickname_column = np.empty(len(output))  \n",
    "    output['nickname'] = nickname_column\n",
    "    output['nickname'] = nickname\n",
    "    \n",
    "    #generating a column with nicknames with the size of pixel data\n",
    "    nickname_pixel_column = np.empty(len(pixel_count))  \n",
    "    pixel_count['nickname'] = nickname_pixel_column\n",
    "    pixel_count['nickname'] = nickname\n",
    "    \n",
    "\n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    activity_data.append(output)\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    pixel_data.append(pixel_count)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframe\n",
    "activity_data = pd.concat(activity_data)\n",
    "\n",
    "#Joinning all elements of the array in a dataframe\n",
    "pixel_data = pd.concat(pixel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88a7f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing empty cells with zeros\n",
    "activity_data['ACTIVITY'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5c106ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting pixel dataframe to have nicknames as columns\n",
    "pivoted_pixel_data = pd.pivot_table(pixel_data, values='PIXEL_COUNT', index=pixel_data.index.values,columns=['nickname'])\n",
    "#Restarting index to activate the large'index' as a column\n",
    "pivoted_pixel_data = pivoted_pixel_data.reset_index()\n",
    "pivoted_pixel_data = pivoted_pixel_data.drop('index', 1)\n",
    "#Sorting column values to put nans at the end ignoring the index\n",
    "for col in pivoted_pixel_data:\n",
    "    pivoted_pixel_data[col] = pivoted_pixel_data[col].sort_values(ignore_index=True)\n",
    "# Drop rows which contain all NaN values\n",
    "pivoted_pixel_data = pivoted_pixel_data.dropna(axis=0, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b74ade5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging activity and volume ratio to filter activity where the volume ratio is below 50%\n",
    "filtered_activity_data = pd.merge(activity_data,\n",
    "                                  volumes_data[['raw','SAMPLE','volumes_ratio']],\n",
    "                                  on=['raw','SAMPLE'],\n",
    "                                  how='left')\n",
    "filtered_activity_data.loc[(filtered_activity_data['volumes_ratio'] < 0.5),'ACTIVITY'] = ''\n",
    "# filtered_activity_data['ACTIVITY'] = filtered_activity_data['ACTIVITY'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9131e63f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DENSITY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DENSITY'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-2a8bac276d04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#         print('yes')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#         density['DENSITY'] = density['ACTIVITY']/density['VOLUME_IN_TISSUE']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mdensity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DENSITY'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdensity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ACTIVITY'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdensity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'VOLUME_IN_TISSUE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdensity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ACTIVITY'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DENSITY'"
     ]
    }
   ],
   "source": [
    "#Creating density dataframe\n",
    "##Merging activity, volume and volume in tissue dataframes\n",
    "density = pd.merge(activity_data,\n",
    "                                  volumes_data[['raw','SAMPLE','VOLUME']],\n",
    "                                  on=['raw','SAMPLE'],\n",
    "                                  how='left')\n",
    "density = pd.merge(density,\n",
    "                           volume_intissue_data[['raw','SAMPLE','VOLUME_IN_TISSUE']],\n",
    "                           on=['raw','SAMPLE'],\n",
    "                           how='left')\n",
    "\n",
    "\n",
    "# def density_calc(x):\n",
    "#     if type(x) = float:\n",
    "#         return x > mean_income\n",
    "#     else:\n",
    "\n",
    "# df['higher_than_avg_income'] = df['income'].map(higher_income)\n",
    "# print(df)\n",
    "\n",
    "\n",
    "#  density['DENSITY'] = density['ACTIVITY'].map({True: 'Yes', False: 'No'})\n",
    "\n",
    "# for item in density['ACTIVITY']:\n",
    "#     if isinstance(item, float):\n",
    "# #         print('yes')\n",
    "# #         density['DENSITY'] = density['ACTIVITY']/density['VOLUME_IN_TISSUE']\n",
    "#         density['DENSITY'].loc[density['ACTIVITY'] == item] = item / (density['VOLUME_IN_TISSUE'].loc[density['ACTIVITY'] == item])\n",
    "\n",
    "#     else:\n",
    "#         print(item)\n",
    "# #         density['DENSITY'] = ''\n",
    "\n",
    "#Creating the density nickname (d_nickname)\n",
    "density['d_nickname'] = 'd_' + density['nickname']\n",
    "\n",
    "#Pivoting dataframe to have d_nicknames as columns\n",
    "pivoted_density = pd.pivot_table(density, values='DENSITY', \n",
    "                                       index=['raw'],columns=['d_nickname'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8288b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "density.to_csv('density.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cdc209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting activity dataframe to have nicknames as columns\n",
    "pivoted_activity_data = pd.pivot_table(filtered_activity_data, values='ACTIVITY', \n",
    "                               index=['raw','hemisphere','marker'],columns=['nickname'], aggfunc=np.sum)\n",
    "\n",
    "#Restarting index to activate'hemisphere','marker'and 'rater' as columns\n",
    "pivoted_activity_data = pivoted_activity_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd92228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conbinning all dataframes to create the \"master\" dataframe\n",
    "master_data = pd.merge(filtered_activity_data, density, on=['IDPath','LabelID','raw','LabelAbrv','SAMPLE', 'nickname','hemisphere','marker','TX_GROUP','nickname'], how='left')\n",
    "master_data.rename(columns = {'ACTIVITY_x':'ACTIVITY'}, inplace = True)\n",
    "master_data.drop(['ACTIVITY_y','d_nickname'], inplace=True, axis=1)\n",
    "master_data['SAMPLE'] = master_data['SAMPLE'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d95af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all pivoted dataframes\n",
    "gubra_and_activity = pd.merge(brain_gubra_map,pivoted_activity_data,on='raw',how='right')\n",
    "cell_count_output = pd.merge(gubra_and_activity,pivoted_volumes_data,on='raw',how='left')\n",
    "cell_count_output = pd.merge(cell_count_output,pivoted_density,on='raw',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3028a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combinning volumes and densities separately with the brain map (similar to gubra_and_activity)\n",
    "gubra_and_volumes = pd.merge(brain_gubra_map,pivoted_volumes_data,on='raw',how='right')\n",
    "gubra_and_densities = pd.merge(brain_gubra_map,pivoted_density,on='raw',how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705743f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the main path\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46109d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the \"master_dataframe_output.csv\" file\n",
    "master_data.to_csv('master_dataframe_output.csv', index=False)\n",
    "\n",
    "#creating the \"cell_vols_dens_output.csv\" file\n",
    "cell_count_output.to_csv('GUBRA_cell_vols_dens_output.csv', index=False)\n",
    "#creating the \"cell_output.csv\" file\n",
    "gubra_and_activity.to_csv('GUBRA_cell_output.csv', index=False)\n",
    "#creating the \"vols_output.csv\" file\n",
    "gubra_and_volumes.to_csv('GUBRA_vols_output.csv', index=False)\n",
    "#creating the \"dens_output.csv\" file\n",
    "gubra_and_densities.to_csv('GUBRA_dens_output.csv', index=False)\n",
    "\n",
    "#creating the \"pixel_count_output.csv\" file\n",
    "pivoted_pixel_data.to_csv('pixel_count_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa3fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting pixel histograms\n",
    "# pixel_columns = pivoted_pixel_data.columns.values\n",
    "\n",
    "fig, axes = plt.subplots(len(pivoted_pixel_data.columns)//4, 4, figsize=(48, 48))\n",
    "\n",
    "i = 0\n",
    "for triaxis in axes:\n",
    "    for axis in triaxis:\n",
    "        pivoted_pixel_data.hist(column = pivoted_pixel_data.columns[i], bins = 100, ax=axis, color='#C1CDCD')\n",
    "        axis.set_title(pivoted_pixel_data.columns[i],pad=20, fontdict={'fontsize':40})\n",
    "        axis.set_yscale('log')\n",
    "        axis.set_ylabel('counts',fontdict={'fontsize':30})\n",
    "        axis.set_xlabel('pixel size',fontdict={'fontsize':30})\n",
    "        axis.tick_params(labelsize=24)\n",
    "        mean = pivoted_pixel_data[pivoted_pixel_data.columns[i]].mean()\n",
    "        mean = round(mean,1)\n",
    "        median = pivoted_pixel_data[pivoted_pixel_data.columns[i]].median()\n",
    "        mode = pivoted_pixel_data[pivoted_pixel_data.columns[i]].mode()\n",
    "        mode = np.take(mode.values,0)\n",
    "\n",
    "        axis.axvline(mean, color='r', linestyle='--', linewidth= 3)\n",
    "        axis.axvline(median, color='g', linestyle='--', linewidth= 3)\n",
    "        axis.axvline(mode, color='b', linestyle='--', linewidth= 3)\n",
    "        axis.legend({'Mean = {}'.format(mean):mean,'Median = {}'.format(median):median,'Mode = {}'.format(mode):mode},prop={'size': 30})\n",
    "\n",
    "        i = i+1\n",
    "        \n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.savefig('pixel_histograms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1100c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ending timming process\n",
    "end = time.time()\n",
    "\n",
    "# Printing how many files were processed and how much time the process took\n",
    "files_processed = number_activity_files = number_files+ number_volume_files + number_volintissue_files\n",
    "print(files_processed,' Files processed ')\n",
    "print(' ')\n",
    "print(' Execution time:', round((end - start),2), 'seconds') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
