{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d95a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt # importing matplotlib\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "import seaborn as sns\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f246ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stanting timming process\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "488f5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the main directory\n",
    "main_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e012e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subfolder_name = [f.name for f in os.scandir(main_directory) if f.is_dir()]\n",
    "subfolder_with_path = [\"\" for i in range(4)]\n",
    "subfolder_with_path[0] = main_directory + '/'+'01Activity_files'\n",
    "subfolder_with_path[1] = main_directory + '/'+'02Volume_files'\n",
    "subfolder_with_path[2] = main_directory + '/'+'03Volume_in_tissue_files'\n",
    "subfolder_with_path[3] = main_directory + '/'+'zzz_input_and_reference_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83625283",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Importing information from \"samples overview\", \"intensisties template\" and \"brain allen map\"\n",
    "###############################################################################################\n",
    "\n",
    "# Changing directory to the \"zzz_input_and_reference_files\" folder\n",
    "os.chdir(subfolder_with_path[-1])\n",
    "\n",
    "\n",
    "# Reading \"sample_overview.csv\" file\n",
    "samples_overview = pd.read_csv(\"sample_overview.csv\", \n",
    "                               dtype={\"MOUSE\": \"string\",\"SAMPLE\": int,\n",
    "                                      \"FILES_HD\": int,\"FILES_BOX\": int,\n",
    "                                      \"hemisphere\": \"string\",\"MARKER\": \"string\",\n",
    "                                      \"TX_GROUP\": \"string\", \n",
    "                                      \"GENDER\":\"string\", \n",
    "                                      \"CONTEXT\":\"string\"})\n",
    "\n",
    "# Reading \"gubra_intensities_template.csv\" file\n",
    "gubra_intensities_template = pd.read_csv(\"gubra_intensities_template_fixed_080922.csv\",\n",
    "                                   dtype={\"IDPath\": \"string\", \n",
    "                                          \"LabelID\": int, \n",
    "                                          \"raw\": \"string\", \n",
    "                                          \"LabelAbrv\": \"string\"})\n",
    "# Reading \"brain_allen_map.csv\" file\n",
    "brain_gubra_map = pd.read_csv(\"brain_gubra_map_fixed_080822.csv\", \n",
    "                               dtype={\"IDPath\": \"string\", \"LabelAbrv\": \"string\",\n",
    "                                      \"raw\": \"string\",\"allen_1\": \"string\",\n",
    "                                      \"allen_2\": \"string\",\"allen_3\": \"string\",\n",
    "                                      \"allen_4\": \"string\",\"allen_5\": \"string\",\n",
    "                                      \"allen_6\": \"string\",\"allen_7\": \"string\",\n",
    "                                      \"fine\": \"string\",\"medium\": \"string\",\n",
    "                                      \"coarse\": \"string\", \"all\":\"string\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c4188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2723b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving drugs and markers' names from the \"sample_overview\" file\n",
    "\n",
    "drugs = samples_overview['TX_GROUP'].unique()\n",
    "markers = samples_overview['marker'].unique()\n",
    "\n",
    "d = 0\n",
    "m = 0\n",
    "counters_names = []\n",
    "while (m < len(markers)):\n",
    "    while (d < len(drugs)):\n",
    "        counters_names.append(drugs[d] + '_' + markers[m])\n",
    "        d += 1\n",
    "    m += 1\n",
    "    d = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6547ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"02Volume_files\" folder\n",
    "os.chdir(subfolder_with_path[1])\n",
    "\n",
    "#Counting number of files on \"02Volume_files\" folder\n",
    "list = os.listdir(subfolder_with_path[1]) \n",
    "number_files = len(list)\n",
    "number_volume_files = number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f3f7eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using and timing  a loop to process all files and populate the main data-frame\n",
    "\n",
    "volume_data = [] #This array will contain df as elements\n",
    "\n",
    "i = 0\n",
    "while i < number_files:\n",
    "\n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "    \n",
    "    file = list[i]\n",
    "    # Saving sample's number\n",
    "    filename_segmented = file.split('_')\n",
    "    sample = filename_segmented[1]\n",
    "\n",
    "\n",
    "    # Reading file's data\n",
    "    header = [\"PIXEL_COUNT\"]\n",
    "    pixels_count_volume = pd.read_csv(file, names = header)\n",
    "    pixels_count_volume.insert(0, column = 'INTENSITY', value = range(0, len(pixels_count_volume))) \n",
    "\n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(pixels_count_volume, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    volume_label_name = 'VOLUME'\n",
    "    output = output.rename(columns = {'PIXEL_COUNT':volume_label_name})\n",
    "    output['VOLUME'] = output['VOLUME'].div(1000000).round(7)\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "   \n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    volume_data.append(output)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframe\n",
    "volume_data = pd.concat(volume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ffaf238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31a5014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"03Volume_in_tissue_files\" folder\n",
    "os.chdir(subfolder_with_path[2])\n",
    "\n",
    "#Counting number of files on \"03Volume_in_tissue_files\" folder\n",
    "list = os.listdir(subfolder_with_path[2]) \n",
    "number_files = len(list)\n",
    "number_volintissue_files = number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5d028ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using and timing  a loop to process all files and populate the main data-frame\n",
    "\n",
    "volume_intissue_data = [] #This array will contain df as elements\n",
    "\n",
    "#Staring counters\n",
    "\n",
    "i = 0 #General loop counter\n",
    "\n",
    "\n",
    "#Zeroing the counters \n",
    "counters = np.zeros(len(counters_names))\n",
    "\n",
    "#Creating counters array to contain sample's names as elements\n",
    "counters_samples = [[] for j in range(len(counters_names))]\n",
    "\n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "\n",
    "while i < number_files:\n",
    "\n",
    "\n",
    "    file = list[i]\n",
    "    # Saving sample's number \n",
    "    filename_segmented = file.split('_')\n",
    "    sample = filename_segmented[1]\n",
    "\n",
    "    # Reading file's data\n",
    "    header = [\"PIXEL_COUNT\"]\n",
    "    pixels_count_volume = pd.read_csv(file, names = header)\n",
    "    pixels_count_volume.insert(0, column = 'INTENSITY', value = range(0, len(pixels_count_volume))) \n",
    "\n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(pixels_count_volume, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    volume_label_name = 'VOLUME_IN_TISSUE'\n",
    "    output = output.rename(columns = {'PIXEL_COUNT':volume_label_name})\n",
    "    output['VOLUME_IN_TISSUE'] = output['VOLUME_IN_TISSUE'].div(1000000).round(6)\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Merging activity and sample overview data-frames\n",
    "    output= pd.merge(output,samples_overview[['SAMPLE',\n",
    "                                             'hemisphere','marker',\n",
    "                                             'TX_GROUP']],on='SAMPLE',how='inner')\n",
    "    \n",
    "    #Adding a column with the sample's nickname\n",
    "\n",
    "    counters_index = counters_names.index(output['TX_GROUP'].iloc[0] + '_' + output['marker'].iloc[0])\n",
    "    if output['SAMPLE'].iloc[0] not in counters_samples[counters_index]:\n",
    "        counters[counters_index] += 1\n",
    "        counters_samples[counters_index].append(output['SAMPLE'].iloc[0])\n",
    "        nickname = 'v' + output['TX_GROUP'].iloc[0] + '_' + str(int(counters[counters_index]))\n",
    "\n",
    "    nickname_column = np.empty(len(output))    \n",
    "    output['nickname'] = nickname_column\n",
    "    output['nickname'] = nickname\n",
    "    \n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    volume_intissue_data.append(output)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframeo\n",
    "volume_intissue_data = pd.concat(volume_intissue_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad7ff9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating volume ratio\n",
    "volumes_data = pd.merge(volume_intissue_data,volume_data[['raw','VOLUME','SAMPLE']],on=('raw','SAMPLE'),how='left')\n",
    "volumes_data['volumes_ratio'] = volumes_data['VOLUME_IN_TISSUE'] / volumes_data['VOLUME'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a8b4207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting dataframe to have nicknames as columns\n",
    "pivoted_volumes_data = pd.pivot_table(volumes_data, values='VOLUME_IN_TISSUE', \n",
    "                                       index=['raw'],columns=['nickname'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9643587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"01Activity_files\" folder\n",
    "os.chdir(subfolder_with_path[0])\n",
    "\n",
    "#Counting number of files on \"01Activity_files\" folder\n",
    "list = os.listdir(subfolder_with_path[0]) \n",
    "number_files = len(list)\n",
    "number_activity_files = number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fed307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using and timing  a loop to process all files and populate the main data-frame\n",
    "\n",
    "activity_data = [] #This array will contain df as elements\n",
    "\n",
    "# Extractiing pixel information\n",
    "pixel_data = [] #This array will contain df as elements\n",
    "\n",
    "#Starting counters\n",
    "\n",
    "i = 0 #General loop counter\n",
    "\n",
    "#Zeroing the counters \n",
    "counters = np.zeros(len(counters_names))\n",
    "\n",
    "#Creating counters array to contain sample's names as elements\n",
    "counters_samples = [[] for j in range(len(counters_names))]\n",
    "\n",
    "\n",
    "    ##############################################\n",
    "    # Innitiates loop to process each file\n",
    "    ##############################################\n",
    "\n",
    "\n",
    "while i < number_files:\n",
    "\n",
    "    # Working with each file at a time\n",
    "    file = list[i]\n",
    "    \n",
    "    # Saving sample's number\n",
    "    filename_segmented = file.split('_')\n",
    "    sample = filename_segmented[1]\n",
    "\n",
    "    # Reading file's data\n",
    "    regions_count_activity_fracc = pd.read_csv(file,low_memory=False)\n",
    "    #Cleanning row that have the srting \"PIXEL_COUNT\" instead of values\n",
    "    regions_count_activity_fracc = regions_count_activity_fracc[regions_count_activity_fracc.PIXEL_COUNT != \"PIXEL_COUNT\"] \n",
    "    #Filtering rows where the pixel counts is repeated more than 10 times\n",
    "    regions_count_activity_fracc =  regions_count_activity_fracc.groupby('PIXEL_COUNT').filter(lambda x : len(x)>10)\n",
    "    \n",
    "    # Storing pixel counts of each file\n",
    "    pixel_count = regions_count_activity_fracc[[\"PIXEL_COUNT\"]]\n",
    "    pixel_count = pixel_count.astype(float)\n",
    "\n",
    "    # Adding-up regions' fracctions\n",
    "    regions_fracc_1 = regions_count_activity_fracc[[\"INTENSITY_1\", \"INTENSITY_1_PERC\"]]\n",
    "    regions_fracc_2 = regions_count_activity_fracc[[\"INTENSITY_2\", \"INTENSITY_2_PERC\"]]\n",
    "    regions_fracc_3 = regions_count_activity_fracc[[\"INTENSITY_3\", \"INTENSITY_3_PERC\"]]\n",
    "    regions_fracc_1 = regions_fracc_1.rename(columns={\"INTENSITY_1\": \"INTENSITY\",\"INTENSITY_1_PERC\" : \"COUNTS\"})\n",
    "    regions_fracc_2 = regions_fracc_2.rename(columns={\"INTENSITY_2\": \"INTENSITY\",\"INTENSITY_2_PERC\" : \"COUNTS\"})\n",
    "    regions_fracc_3 = regions_fracc_3.rename(columns={\"INTENSITY_3\": \"INTENSITY\",\"INTENSITY_3_PERC\" : \"COUNTS\"})\n",
    "    total_region_activity = regions_fracc_1.append(regions_fracc_2, \n",
    "                                                   ignore_index=True).append(regions_fracc_3, ignore_index=True)\n",
    "    total_region_activity[\"COUNTS\"] = total_region_activity[\"COUNTS\"].astype(float)\n",
    "    total_region_activity = total_region_activity.groupby(['INTENSITY']).agg('sum').reset_index()\n",
    "#     total_region_activity[\"COUNTS\"] = total_region_activity[\"COUNTS\"].round(0)\n",
    "    total_region_activity[\"INTENSITY\"] = total_region_activity[\"INTENSITY\"].astype(int)\n",
    "        \n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(total_region_activity, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    activity_label_name = 'ACTIVITY'\n",
    "    output = output.rename(columns = {'COUNTS':activity_label_name})\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Merging activity and sample overview data-frames\n",
    "    output= pd.merge(output,samples_overview[['SAMPLE',\n",
    "                                             'hemisphere','marker',\n",
    "                                             'TX_GROUP']],on='SAMPLE',how='inner')\n",
    "    \n",
    "    \n",
    "    #Adding a column with the sample's nickname\n",
    "\n",
    "    counters_index = counters_names.index(output['TX_GROUP'].iloc[0] + '_' + output['marker'].iloc[0])\n",
    "    if output['SAMPLE'].iloc[0] not in counters_samples[counters_index]:\n",
    "        counters[counters_index] += 1\n",
    "        counters_samples[counters_index].append(output['SAMPLE'].iloc[0])\n",
    "        nickname = output['TX_GROUP'].iloc[0] + '_' + str(int(counters[counters_index]))\n",
    "\n",
    "    nickname_column = np.empty(len(output))  \n",
    "    output['nickname'] = nickname_column\n",
    "    output['nickname'] = nickname\n",
    "    \n",
    "    #generating a column with nicknames with the size of pixel data\n",
    "    nickname_pixel_column = np.empty(len(pixel_count))  \n",
    "    pixel_count['nickname'] = nickname_pixel_column\n",
    "    pixel_count['nickname'] = nickname\n",
    "    \n",
    "\n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    activity_data.append(output)\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    pixel_data.append(pixel_count)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframe\n",
    "activity_data = pd.concat(activity_data)\n",
    "\n",
    "#Joinning all elements of the array in a dataframe\n",
    "pixel_data = pd.concat(pixel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88a7f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing empty cells with zeros\n",
    "activity_data['ACTIVITY'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5c106ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting pixel dataframe to have nicknames as columns\n",
    "pivoted_pixel_data = pd.pivot_table(pixel_data, values='PIXEL_COUNT', index=pixel_data.index.values,columns=['nickname'])\n",
    "#Restarting index to activate the large'index' as a column\n",
    "pivoted_pixel_data = pivoted_pixel_data.reset_index()\n",
    "pivoted_pixel_data = pivoted_pixel_data.drop('index', 1)\n",
    "#Sorting column values to put nans at the end ignoring the index\n",
    "for col in pivoted_pixel_data:\n",
    "    pivoted_pixel_data[col] = pivoted_pixel_data[col].sort_values(ignore_index=True)\n",
    "# Drop rows which contain all NaN values\n",
    "pivoted_pixel_data = pivoted_pixel_data.dropna(axis=0, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "036414d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging activity and volume ratio to filter activity where the volume ratio is below 50%\n",
    "filtered_activity_data = pd.merge(activity_data,\n",
    "                                  volumes_data[['raw','SAMPLE','volumes_ratio']],\n",
    "                                  on=['raw','SAMPLE'],\n",
    "                                  how='left')\n",
    "filtered_activity_data.loc[(filtered_activity_data['volumes_ratio'] < 0.5),'ACTIVITY'] = ''\n",
    "# filtered_activity_data['ACTIVITY'] = filtered_activity_data['ACTIVITY'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9131e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating density dataframe\n",
    "##Merging activity, volume and volume in tissue dataframes\n",
    "density = pd.merge(activity_data,\n",
    "                                  volumes_data[['raw','SAMPLE','VOLUME']],\n",
    "                                  on=['raw','SAMPLE'],\n",
    "                                  how='left')\n",
    "density = pd.merge(density,\n",
    "                           volume_intissue_data[['raw','SAMPLE','VOLUME_IN_TISSUE']],\n",
    "                           on=['raw','SAMPLE'],\n",
    "                           how='left')\n",
    "#Calculting density\n",
    "density['DENSITY'] = density['ACTIVITY']/density['VOLUME_IN_TISSUE']\n",
    "\n",
    "#Creating the density nickname (d_nickname)\n",
    "density['d_nickname'] = 'd_' + density['nickname']\n",
    "\n",
    "#Assigning a value of N/A whenever the VOLUME_IN_TISSUE = 0\n",
    "density.loc[df[\"VOLUME_IN_TISSUE\"] == 0, \"DENSITY\"] = 'N/A'\n",
    "\n",
    "#Pivoting dataframe to have d_nicknames as columns\n",
    "pivoted_density = pd.pivot_table(density, values='DENSITY', \n",
    "                                       index=['raw'],columns=['d_nickname'], aggfunc=np.sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cdc209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting activity dataframe to have nicknames as columns\n",
    "pivoted_activity_data = pd.pivot_table(filtered_activity_data, values='ACTIVITY', \n",
    "                               index=['raw','hemisphere','marker'],columns=['nickname'], aggfunc=np.sum)\n",
    "\n",
    "#Restarting index to activate'hemisphere','marker'and 'rater' as columns\n",
    "pivoted_activity_data = pivoted_activity_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd92228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conbinning all dataframes to create the \"master\" dataframe\n",
    "master_data = pd.merge(filtered_activity_data, density, on=['IDPath','LabelID','raw','LabelAbrv','SAMPLE', 'nickname','hemisphere','marker','TX_GROUP','nickname'], how='left')\n",
    "master_data.rename(columns = {'ACTIVITY_x':'ACTIVITY'}, inplace = True)\n",
    "master_data.drop(['ACTIVITY_y','d_nickname'], inplace=True, axis=1)\n",
    "master_data['SAMPLE'] = master_data['SAMPLE'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d95af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all pivoted dataframes\n",
    "gubra_and_activity = pd.merge(brain_gubra_map,pivoted_activity_data,on='raw',how='right')\n",
    "cell_count_output = pd.merge(gubra_and_activity,pivoted_volumes_data,on='raw',how='left')\n",
    "cell_count_output = pd.merge(cell_count_output,pivoted_density,on='raw',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3028a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combinning volumes and densities separately with the brain map (similar to gubra_and_activity)\n",
    "gubra_and_volumes = pd.merge(brain_gubra_map,pivoted_volumes_data,on='raw',how='right')\n",
    "gubra_and_densities = pd.merge(brain_gubra_map,pivoted_density,on='raw',how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705743f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the main path\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46109d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the \"master_dataframe_output.csv\" file\n",
    "master_data.to_csv('master_dataframe_output.csv', index=False)\n",
    "\n",
    "#creating the \"cell_vols_dens_output.csv\" file\n",
    "cell_count_output.to_csv('GUBRA_cell_vols_dens_output.csv', index=False)\n",
    "#creating the \"cell_output.csv\" file\n",
    "gubra_and_activity.to_csv('GUBRA_cell_output.csv', index=False)\n",
    "#creating the \"vols_output.csv\" file\n",
    "gubra_and_volumes.to_csv('GUBRA_vols_output.csv', index=False)\n",
    "#creating the \"dens_output.csv\" file\n",
    "gubra_and_densities.to_csv('GUBRA_dens_output.csv', index=False)\n",
    "\n",
    "#creating the \"pixel_count_output.csv\" file\n",
    "pivoted_pixel_data.to_csv('pixel_count_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa3fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting pixel histograms\n",
    "# pixel_columns = pivoted_pixel_data.columns.values\n",
    "\n",
    "fig, axes = plt.subplots(len(pivoted_pixel_data.columns)//4, 4, figsize=(48, 48))\n",
    "\n",
    "i = 0\n",
    "for triaxis in axes:\n",
    "    for axis in triaxis:\n",
    "        pivoted_pixel_data.hist(column = pivoted_pixel_data.columns[i], bins = 100, ax=axis, color='#C1CDCD')\n",
    "        axis.set_title(pivoted_pixel_data.columns[i],pad=20, fontdict={'fontsize':40})\n",
    "        axis.set_yscale('log')\n",
    "        axis.set_ylabel('counts',fontdict={'fontsize':30})\n",
    "        axis.set_xlabel('pixel size',fontdict={'fontsize':30})\n",
    "        axis.tick_params(labelsize=24)\n",
    "        mean = pivoted_pixel_data[pivoted_pixel_data.columns[i]].mean()\n",
    "        mean = round(mean,1)\n",
    "        median = pivoted_pixel_data[pivoted_pixel_data.columns[i]].median()\n",
    "        mode = pivoted_pixel_data[pivoted_pixel_data.columns[i]].mode()\n",
    "        mode = np.take(mode.values,0)\n",
    "\n",
    "        axis.axvline(mean, color='r', linestyle='--', linewidth= 3)\n",
    "        axis.axvline(median, color='g', linestyle='--', linewidth= 3)\n",
    "        axis.axvline(mode, color='b', linestyle='--', linewidth= 3)\n",
    "        axis.legend({'Mean = {}'.format(mean):mean,'Median = {}'.format(median):median,'Mode = {}'.format(mode):mode},prop={'size': 30})\n",
    "\n",
    "        i = i+1\n",
    "        \n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "fig.savefig('pixel_histograms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1100c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ending timming process\n",
    "end = time.time()\n",
    "\n",
    "# Printing how many files were processed and how much time the process took\n",
    "files_processed = number_activity_files = number_files+ number_volume_files + number_volintissue_files\n",
    "print(files_processed,' Files processed ')\n",
    "print(' ')\n",
    "print(' Execution time:', round((end - start),2), 'seconds') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
