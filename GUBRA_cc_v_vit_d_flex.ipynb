{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stanting timming process\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the main directory\n",
    "main_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subfolder_name = [f.name for f in os.scandir(main_directory) if f.is_dir()]\n",
    "subfolder_with_path = [\"\" for i in range(4)]\n",
    "subfolder_with_path[0] = main_directory + '/'+'01Activity_files'\n",
    "subfolder_with_path[1] = main_directory + '/'+'02Volume_files'\n",
    "subfolder_with_path[2] = main_directory + '/'+'03Volume_in_tissue_files'\n",
    "subfolder_with_path[3] = main_directory + '/'+'zzz_input_and_reference_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Importing information from \"samples overview\", \"intensisties template\" and \"brain allen map\"\n",
    "###############################################################################################\n",
    "\n",
    "# Changing directory to the \"zzz_input_and_reference_files\" folder\n",
    "os.chdir(subfolder_with_path[-1])\n",
    "\n",
    "\n",
    "# Reading \"sample_overview.csv\" file\n",
    "samples_overview = pd.read_csv(\"sample_overview.csv\", \n",
    "                               dtype={\"SAMPLE\": int,\n",
    "                                      \"hemisphere\": \"string\",\"marker\": \"string\",\n",
    "                                      \"TX_GROUP\": \"string\"})\n",
    "\n",
    "# Reading \"gubra_intensities_template.csv\" file\n",
    "gubra_intensities_template = pd.read_csv(\"gubra_intensities_template.csv\",\n",
    "                                   dtype={\"IDPath\": \"string\", \n",
    "                                          \"LabelID\": int, \n",
    "                                          \"raw\": \"string\", \n",
    "                                          \"LabelAbrv\": \"string\"})\n",
    "# Reading \"brain_allen_map.csv\" file\n",
    "brain_gubra_map = pd.read_csv(\"brain_gubra_map_fixed.csv\", \n",
    "                               dtype={\"IDPath\": \"string\", \"LabelAbrv\": \"string\",\n",
    "                                      \"raw\": \"string\",\"allen_1\": \"string\",\n",
    "                                      \"allen_2\": \"string\",\"allen_3\": \"string\",\n",
    "                                      \"allen_4\": \"string\",\"allen_5\": \"string\",\n",
    "                                      \"allen_6\": \"string\",\"allen_7\": \"string\",\n",
    "                                      \"fine\": \"string\",\"medium\": \"string\",\n",
    "                                      \"coarse\": \"string\", \"all\":\"string\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving drugs and markers' names from the \"sample_overview\" file\n",
    "\n",
    "drugs = samples_overview['TX_GROUP'].unique()\n",
    "markers = samples_overview['marker'].unique()\n",
    "\n",
    "d = 0\n",
    "m = 0\n",
    "counters_names = []\n",
    "while (m < len(markers)):\n",
    "    while (d < len(drugs)):\n",
    "        counters_names.append(drugs[d] + '_' + markers[m])\n",
    "        d += 1\n",
    "    m += 1\n",
    "    d = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"02Volume_files\" folder\n",
    "os.chdir(subfolder_with_path[1])\n",
    "\n",
    "#Counting number of files on \"02Volume_files\" folder\n",
    "list = os.listdir(subfolder_with_path[1]) \n",
    "number_files = len(list)\n",
    "number_volume_files = number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using and timing  a loop to process all files and populate the main data-frame\n",
    "\n",
    "volume_data = [] #This array will contain df as elements\n",
    "\n",
    "#Staring counters\n",
    "\n",
    "i = 0 #General loop counter\n",
    "\n",
    "#Zeroing the counters \n",
    "counters = np.zeros(len(counters_names))\n",
    "\n",
    "#Creating counters array to contain sample's names as elements\n",
    "counters_samples = [[] for j in range(len(counters_names))]\n",
    "\n",
    "while i < number_files:\n",
    "\n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "    \n",
    "    file = list[i]\n",
    "    # Saving sample's number\n",
    "    filename_segmented = file.split('_')\n",
    "    sample = filename_segmented[1]\n",
    "\n",
    "\n",
    "    # Reading file's data\n",
    "    header = [\"PIXEL_COUNT\"]\n",
    "    pixels_count_volume = pd.read_csv(file, names = header)\n",
    "    pixels_count_volume.insert(0, column = 'INTENSITY', value = range(0, len(pixels_count_volume))) \n",
    "\n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(pixels_count_volume, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    volume_label_name = 'VOLUME'\n",
    "    output = output.rename(columns = {'PIXEL_COUNT':volume_label_name})\n",
    "    output['VOLUME'] = output['VOLUME'].div(1000000).round(7)\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Merging activity and sample overview data-frames\n",
    "    output= pd.merge(output,samples_overview[['SAMPLE',\n",
    "                                             'hemisphere','marker',\n",
    "                                             'TX_GROUP']],on='SAMPLE',how='inner')\n",
    "    \n",
    "    #Adding a column with the sample's nickname\n",
    "    counters_index = counters_names.index(output['TX_GROUP'].iloc[0] + '_' + output['marker'].iloc[0])\n",
    "    if output['SAMPLE'].iloc[0] not in counters_samples[counters_index]:\n",
    "        counters[counters_index] += 1\n",
    "        counters_samples[counters_index].append(output['SAMPLE'].iloc[0])\n",
    "        nickname = 'v_' + output['TX_GROUP'].iloc[0] + '_' + str(int(counters[counters_index]))\n",
    "\n",
    "    nickname_column = np.empty(len(output))    \n",
    "    output['nickname'] = nickname_column\n",
    "    output['nickname'] = nickname\n",
    "    \n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    volume_data.append(output)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframe\n",
    "volume_data = pd.concat(volume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"03Volume_in_tissue_files\" folder\n",
    "os.chdir(subfolder_with_path[2])\n",
    "\n",
    "#Counting number of files on \"03Volume_in_tissue_files\" folder\n",
    "list = os.listdir(subfolder_with_path[2]) \n",
    "number_files = len(list)\n",
    "number_volintissue_files = number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using and timing  a loop to process all files and populate the main data-frame\n",
    "\n",
    "volume_intissue_data = [] #This array will contain df as elements\n",
    "\n",
    "#Staring counters\n",
    "\n",
    "i = 0 #General loop counter\n",
    "\n",
    "#Zeroing the counters \n",
    "counters = np.zeros(len(counters_names))\n",
    "\n",
    "#Creating counters array to contain sample's names as elements\n",
    "counters_samples = [[] for j in range(len(counters_names))]\n",
    "\n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "\n",
    "while i < number_files:\n",
    "\n",
    "\n",
    "    file = list[i]\n",
    "    # Saving sample's number \n",
    "    filename_segmented = file.split('_')\n",
    "    sample = filename_segmented[1]\n",
    "\n",
    "    # Reading file's data\n",
    "    header = [\"PIXEL_COUNT\"]\n",
    "    pixels_count_volume = pd.read_csv(file, names = header)\n",
    "    pixels_count_volume.insert(0, column = 'INTENSITY', value = range(0, len(pixels_count_volume))) \n",
    "\n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(pixels_count_volume, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    volume_label_name = 'VOLUME_IN_TISSUE'\n",
    "    output = output.rename(columns = {'PIXEL_COUNT':volume_label_name})\n",
    "    output['VOLUME_IN_TISSUE'] = output['VOLUME_IN_TISSUE'].div(1000000).round(6)\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Merging activity and sample overview data-frames\n",
    "    output= pd.merge(output,samples_overview[['SAMPLE',\n",
    "                                             'hemisphere','marker',\n",
    "                                             'TX_GROUP']],on='SAMPLE',how='inner')\n",
    "    \n",
    "    #Adding a column with the sample's nickname\n",
    "\n",
    "    counters_index = counters_names.index(output['TX_GROUP'].iloc[0] + '_' + output['marker'].iloc[0])\n",
    "    if output['SAMPLE'].iloc[0] not in counters_samples[counters_index]:\n",
    "        counters[counters_index] += 1\n",
    "        counters_samples[counters_index].append(output['SAMPLE'].iloc[0])\n",
    "        nickname = 'vit_' + output['TX_GROUP'].iloc[0] + '_' + str(int(counters[counters_index]))\n",
    "\n",
    "    nickname_column = np.empty(len(output))    \n",
    "    output['nickname'] = nickname_column\n",
    "    output['nickname'] = nickname\n",
    "    \n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    volume_intissue_data.append(output)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframeo\n",
    "volume_intissue_data = pd.concat(volume_intissue_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating volume ratio\n",
    "volumes_data = pd.merge(volume_intissue_data,volume_data[['raw','VOLUME','SAMPLE']],on=('raw','SAMPLE'),how='left')\n",
    "volumes_data['volumes_ratio'] = volumes_data['VOLUME_IN_TISSUE'] / volumes_data['VOLUME'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting dataframe to have nicknames as columns\n",
    "pivoted_volumesintissue_data = pd.pivot_table(volume_intissue_data, values='VOLUME_IN_TISSUE', \n",
    "                                       index=['raw','SAMPLE'],columns=['nickname'], aggfunc=np.sum)\n",
    "#Restarting index to activate'raw' and 'marker' as columns\n",
    "pivoted_volumesintissue_data = pivoted_volumesintissue_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting dataframe to have nicknames as columns\n",
    "pivoted_volumes_data = pd.pivot_table(volume_data, values='VOLUME', \n",
    "                                       index=['raw', 'SAMPLE'],columns=['nickname'], aggfunc=np.sum)\n",
    "#Restarting index to activate'raw' and 'marker' as columns\n",
    "pivoted_volumes_data = pivoted_volumes_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"01Activity_files\" folder\n",
    "os.chdir(subfolder_with_path[0])\n",
    "\n",
    "#Counting number of files on \"01Activity_files\" folder\n",
    "list = os.listdir(subfolder_with_path[0]) \n",
    "number_files = len(list)\n",
    "number_activity_files = number_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using and timing  a loop to process all files and populate the main data-frame\n",
    "\n",
    "activity_data = [] #This array will contain df as elements\n",
    "\n",
    "#Staring counters\n",
    "\n",
    "i = 0 #General loop counter\n",
    "\n",
    "#Zeroing the counters \n",
    "counters = np.zeros(len(counters_names))\n",
    "\n",
    "#Creating counters array to contain sample's names as elements\n",
    "counters_samples = [[] for j in range(len(counters_names))]\n",
    "\n",
    "\n",
    "    ##############################################\n",
    "    # Innitiates loop to process each file\n",
    "    ##############################################\n",
    "\n",
    "\n",
    "while i < number_files:\n",
    "\n",
    "    # Working with each file at a time\n",
    "    file = list[i]\n",
    "    \n",
    "    # Saving sample's number\n",
    "    filename_segmented = file.split('_')\n",
    "    sample = filename_segmented[1]\n",
    "\n",
    "    # Reading file's data\n",
    "    regions_count_activity_fracc = pd.read_csv(file,low_memory=False)\n",
    "    regions_count_activity_fracc = regions_count_activity_fracc[regions_count_activity_fracc.PIXEL_COUNT != \"PIXEL_COUNT\"]        \n",
    "\n",
    "    # Adding-up regions' fracctions\n",
    "    regions_fracc_1 = regions_count_activity_fracc[[\"INTENSITY_1\", \"INTENSITY_1_PERC\"]]\n",
    "    regions_fracc_2 = regions_count_activity_fracc[[\"INTENSITY_2\", \"INTENSITY_2_PERC\"]]\n",
    "    regions_fracc_3 = regions_count_activity_fracc[[\"INTENSITY_3\", \"INTENSITY_3_PERC\"]]\n",
    "    regions_fracc_1 = regions_fracc_1.rename(columns={\"INTENSITY_1\": \"INTENSITY\",\"INTENSITY_1_PERC\" : \"COUNTS\"})\n",
    "    regions_fracc_2 = regions_fracc_2.rename(columns={\"INTENSITY_2\": \"INTENSITY\",\"INTENSITY_2_PERC\" : \"COUNTS\"})\n",
    "    regions_fracc_3 = regions_fracc_3.rename(columns={\"INTENSITY_3\": \"INTENSITY\",\"INTENSITY_3_PERC\" : \"COUNTS\"})\n",
    "    total_region_activity = regions_fracc_1.append(regions_fracc_2, \n",
    "                                                   ignore_index=True).append(regions_fracc_3, ignore_index=True)\n",
    "    total_region_activity[\"COUNTS\"] = total_region_activity[\"COUNTS\"].astype(float)\n",
    "    total_region_activity = total_region_activity.groupby(['INTENSITY']).agg('sum').reset_index()\n",
    "#     total_region_activity[\"COUNTS\"] = total_region_activity[\"COUNTS\"].round(0)\n",
    "    total_region_activity[\"INTENSITY\"] = total_region_activity[\"INTENSITY\"].astype(int)\n",
    "        \n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(total_region_activity, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    activity_label_name = 'ACTIVITY'\n",
    "    output = output.rename(columns = {'COUNTS':activity_label_name})\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Merging activity and sample overview data-frames\n",
    "    output= pd.merge(output,samples_overview[['SAMPLE',\n",
    "                                             'hemisphere','marker',\n",
    "                                             'TX_GROUP']],on='SAMPLE',how='inner')\n",
    "    \n",
    "    \n",
    "    #Adding a column with the sample's nickname\n",
    "\n",
    "    counters_index = counters_names.index(output['TX_GROUP'].iloc[0] + '_' + output['marker'].iloc[0])\n",
    "    if output['SAMPLE'].iloc[0] not in counters_samples[counters_index]:\n",
    "        counters[counters_index] += 1\n",
    "        counters_samples[counters_index].append(output['SAMPLE'].iloc[0])\n",
    "        nickname = output['TX_GROUP'].iloc[0] + '_' + str(int(counters[counters_index]))\n",
    "\n",
    "    nickname_column = np.empty(len(output))    \n",
    "    output['nickname'] = nickname_column\n",
    "    output['nickname'] = nickname\n",
    "\n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    activity_data.append(output)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframe\n",
    "activity_data = pd.concat(activity_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing empty cells with zeros\n",
    "activity_data['ACTIVITY'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating density dataframe\n",
    "##Merging activity, volume and volume in tissue dataframes\n",
    "density = pd.merge(activity_data,\n",
    "                                  volumes_data[['raw','SAMPLE','VOLUME']],\n",
    "                                  on=['raw','SAMPLE'],\n",
    "                                  how='left')\n",
    "density = pd.merge(density,\n",
    "                           volume_intissue_data[['raw','SAMPLE','VOLUME_IN_TISSUE']],\n",
    "                           on=['raw','SAMPLE'],\n",
    "                           how='left')\n",
    "#Creating the density nickname (d_nickname)\n",
    "density['DENSITY'] = density['ACTIVITY'] / density['VOLUME_IN_TISSUE']\n",
    "\n",
    "# Changing directory to the main path\n",
    "os.chdir(main_directory)\n",
    "#Printing all columns\n",
    "density.to_csv('GUBRA_output_all_columns.csv', index=False)\n",
    "\n",
    "density['d_nickname'] = 'd_' + density['nickname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting dataframe to have d_nicknames as columns\n",
    "pivoted_density = pd.pivot_table(density, values='DENSITY', \n",
    "                                       index=['raw', 'SAMPLE'],columns=['d_nickname'], aggfunc=np.sum)\n",
    "#Restarting index to activate'raw' and 'marker' as columns\n",
    "pivoted_density = pivoted_density.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging activity and volume ratio to filter activity where the volume ratio is below 50%\n",
    "filtered_activity_data = pd.merge(activity_data,\n",
    "                                  volumes_data[['raw','SAMPLE','volumes_ratio']],\n",
    "                                  on=['raw','SAMPLE'],\n",
    "                                  how='left')\n",
    "filtered_activity_data.loc[(filtered_activity_data['volumes_ratio'] < 0.5),'ACTIVITY'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoting dataframe to have nicknames as columns\n",
    "pivoted_activity_data = pd.pivot_table(filtered_activity_data, values='ACTIVITY', \n",
    "                               index=['raw','hemisphere','marker','SAMPLE'],columns=['nickname'], aggfunc=np.sum)\n",
    "\n",
    "#Restarting index to activate'hemisphere','marker'and 'rater' as columns\n",
    "pivoted_activity_data = pivoted_activity_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all dataframes\n",
    "gubra_and_activity = pd.merge(brain_gubra_map,pivoted_activity_data,on='raw',how='right')\n",
    "cell_count_output = pd.merge(gubra_and_activity,pivoted_volumesintissue_data,on=['raw','SAMPLE'],how='left')\n",
    "cell_count_output = pd.merge(cell_count_output,pivoted_volumes_data,on=['raw','SAMPLE'],how='left')\n",
    "cell_count_output = pd.merge(cell_count_output,pivoted_density,on=['raw','SAMPLE'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the main path\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the \"cell_count_output.csv\" file\n",
    "cell_count_output.to_csv('GUBRA_output_for_ADX.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SAMPLE</th>\n",
       "      <th>raw</th>\n",
       "      <th>hemisphere</th>\n",
       "      <th>marker</th>\n",
       "      <th>sample43</th>\n",
       "      <th>sample44</th>\n",
       "      <th>sample46</th>\n",
       "      <th>sample47</th>\n",
       "      <th>sample48</th>\n",
       "      <th>sample50</th>\n",
       "      <th>sample51</th>\n",
       "      <th>sample52</th>\n",
       "      <th>sample53</th>\n",
       "      <th>sample54</th>\n",
       "      <th>sample56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abducens_nucleus</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.658</td>\n",
       "      <td>29.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>49.094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.155</td>\n",
       "      <td>93.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abducens_nucleus</td>\n",
       "      <td>right</td>\n",
       "      <td>tdt</td>\n",
       "      <td>14.395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accessory_facial_motor_nucleus</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.574</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.167</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accessory_facial_motor_nucleus</td>\n",
       "      <td>right</td>\n",
       "      <td>tdt</td>\n",
       "      <td>1.553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accessory_olfactory_bulb_glomerular_layer</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>478.013</td>\n",
       "      <td>613.364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.545</td>\n",
       "      <td>261.779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260.535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>437.368</td>\n",
       "      <td>364.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>ventral_tegmental_decussation</td>\n",
       "      <td>right</td>\n",
       "      <td>tdt</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>vestibular_nerve</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.269</td>\n",
       "      <td>24.406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.585</td>\n",
       "      <td>30.701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.827</td>\n",
       "      <td>20.268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>vestibular_nerve</td>\n",
       "      <td>right</td>\n",
       "      <td>tdt</td>\n",
       "      <td>32.765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>vomeronasal_nerve</td>\n",
       "      <td>left</td>\n",
       "      <td>cfos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.476</td>\n",
       "      <td>22.126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.404</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.286</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>vomeronasal_nerve</td>\n",
       "      <td>right</td>\n",
       "      <td>tdt</td>\n",
       "      <td>14.252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "SAMPLE                                        raw hemisphere marker sample43  \\\n",
       "0                                Abducens_nucleus       left   cfos      NaN   \n",
       "1                                Abducens_nucleus      right    tdt   14.395   \n",
       "2                  Accessory_facial_motor_nucleus       left   cfos      NaN   \n",
       "3                  Accessory_facial_motor_nucleus      right    tdt    1.553   \n",
       "4       Accessory_olfactory_bulb_glomerular_layer       left   cfos      NaN   \n",
       "...                                           ...        ...    ...      ...   \n",
       "1180                ventral_tegmental_decussation      right    tdt        0   \n",
       "1181                             vestibular_nerve       left   cfos      NaN   \n",
       "1182                             vestibular_nerve      right    tdt   32.765   \n",
       "1183                            vomeronasal_nerve       left   cfos      NaN   \n",
       "1184                            vomeronasal_nerve      right    tdt   14.252   \n",
       "\n",
       "SAMPLE sample44 sample46 sample47 sample48 sample50 sample51 sample52  \\\n",
       "0        32.658    29.83      NaN      5.5   49.094      NaN  106.743   \n",
       "1           NaN      NaN   12.176      NaN      NaN   75.174      NaN   \n",
       "2         2.574        0      NaN     0.84        0      NaN    3.291   \n",
       "3           NaN      NaN     1.39      NaN      NaN    6.712      NaN   \n",
       "4       478.013  613.364      NaN  175.545  261.779      NaN  260.535   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "1180        NaN      NaN   59.729      NaN      NaN   44.677      NaN   \n",
       "1181     25.269   24.406      NaN   22.585   30.701      NaN   34.746   \n",
       "1182        NaN      NaN   52.162      NaN      NaN  112.306      NaN   \n",
       "1183     23.476   22.126      NaN    9.404               NaN   21.286   \n",
       "1184        NaN      NaN   30.965      NaN      NaN   49.258      NaN   \n",
       "\n",
       "SAMPLE sample53 sample54 sample56  \n",
       "0           NaN   98.155   93.324  \n",
       "1        29.682      NaN      NaN  \n",
       "2           NaN    1.167        2  \n",
       "3         8.657      NaN      NaN  \n",
       "4           NaN  437.368  364.237  \n",
       "...         ...      ...      ...  \n",
       "1180     19.064      NaN      NaN  \n",
       "1181        NaN   66.827   20.268  \n",
       "1182    157.295      NaN      NaN  \n",
       "1183        NaN                    \n",
       "1184     23.339      NaN      NaN  \n",
       "\n",
       "[1185 rows x 14 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating output for Dan's Excel analysis\n",
    "\n",
    "\n",
    "#Chaging SAMPLE elements to integer and then to string when adding the word \"Sample\"\n",
    "# filtered_activity_data['SAMPLE_STR'] = filtered_activity_data['SAMPLE'].astype(int)\n",
    "# filtered_activity_data['SAMPLE_STR'] = filtered_activity_data['SAMPLE_STR'].astype(str)\n",
    "# filtered_activity_data['SAMPLE_STR'] = 'sample' + filtered_activity_data['SAMPLE_STR']\n",
    "\n",
    "#Pivoting dataframe to have sample as columns\n",
    "pivoted_activity_Dan = pd.pivot_table(filtered_activity_data, values='ACTIVITY', \n",
    "                               index=['raw','hemisphere','marker','SAMPLE'],columns=['SAMPLE_STR'], aggfunc=np.sum)\n",
    "\n",
    "#Restarting index to activate'hemisphere','marker' as columns\n",
    "pivoted_activity_Dan = pivoted_activity_Dan.reset_index()\n",
    "\n",
    "pivoted_activity_Dan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the module to ask to the user if they want to print and additional data frame with selected columns\n",
    "# all_columns = density.columns.values\n",
    "# possible_columns = np.delete(all_columns, np.where(all_columns == 'raw'))\n",
    "# possible_columns = np.delete(possible_columns, np.where(possible_columns == 'd_nickname'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33  Files processed \n",
      " \n",
      " Execution time: 16.31 seconds\n"
     ]
    }
   ],
   "source": [
    "#Ending timming process\n",
    "end = time.time()\n",
    "\n",
    "# Printing how many files were processed and how much time the process took\n",
    "files_processed = number_activity_files = number_files+ number_volume_files + number_volintissue_files\n",
    "print(files_processed,' Files processed ')\n",
    "print(' ')\n",
    "print(' Execution time:', round((end - start),2), 'seconds') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
