{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d39dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt # importing matplotlib\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "import seaborn as sns\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d8798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stanting timming process\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e38575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the main directory\n",
    "main_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04da6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subfolder_name = [f.name for f in os.scandir(main_directory) if f.is_dir()]\n",
    "subfolder_with_path = [\"\" for i in range(3)]\n",
    "subfolder_with_path[0] = main_directory + '/'+'ABAcluster_cropped' # cluster files with samples in columns to calulate volumes\n",
    "subfolder_with_path[1] = main_directory + '/'+'ABAconsensus_cropped' # activity files\n",
    "subfolder_with_path[2] = main_directory + '/'+'zzz_input_and_reference_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5527f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Importing information from \"samples overview\", \"intensisties template\" and \"brain allen map\"\n",
    "###############################################################################################\n",
    "\n",
    "# Changing directory to the \"zzz_input_and_reference_files\" folder\n",
    "os.chdir(subfolder_with_path[-1])\n",
    "\n",
    "\n",
    "# Reading \"sample_overview.csv\" file\n",
    "samples_overview = pd.read_csv(\"sample_overview.csv\", \n",
    "                               dtype={\"Sample\": int,\n",
    "                                      \"Side\": \"string\",\n",
    "                                      \"Marker\": \"string\",\n",
    "                                      \"Condition\": \"string\",\n",
    "                                      \"Ort_code\":\"string\",\n",
    "                                      \"488min\":\"string\",\n",
    "                                      \"xy_res\":float,\n",
    "                                      \"z_res\":float,\n",
    "                                      \"olf_bulb\":float,\n",
    "                                      \"Exp_Dir\":\"string\"})\n",
    "\n",
    "# Reading \"gubra_intensities_template.csv\" file\n",
    "gubra_intensities_template = pd.read_csv(\"gubra_intensities_template.csv\",\n",
    "                                   dtype={\"IDPath\": \"string\", \n",
    "                                          \"LabelID\": int, \n",
    "                                          \"raw\": \"string\", \n",
    "                                          \"LabelAbrv\": \"string\"})\n",
    "# Reading \"brain_allen_map.csv\" file\n",
    "brain_gubra_map = pd.read_csv(\"brain_gubra_map_fixed.csv\", \n",
    "                               dtype={\"IDPath\": \"string\", \"LabelAbrv\": \"string\",\n",
    "                                      \"raw\": \"string\",\"allen_1\": \"string\",\n",
    "                                      \"allen_2\": \"string\",\"allen_3\": \"string\",\n",
    "                                      \"allen_4\": \"string\",\"allen_5\": \"string\",\n",
    "                                      \"allen_6\": \"string\",\"allen_7\": \"string\",\n",
    "                                      \"fine\": \"string\",\"medium\": \"string\",\n",
    "                                      \"coarse\": \"string\", \"all\":\"string\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "784dca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving drugs and markers' names from the \"sample_overview\" file\n",
    "\n",
    "drugs = samples_overview['Condition'].unique()\n",
    "markers = samples_overview['Marker'].unique()\n",
    "\n",
    "d = 0\n",
    "m = 0\n",
    "counters_names = []\n",
    "while (m < len(markers)):\n",
    "    while (d < len(drugs)):\n",
    "        counters_names.append(drugs[d] + '_' + markers[m])\n",
    "        d += 1\n",
    "    m += 1\n",
    "    d = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "099f9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing directory to the \"ABAcluster_cropped\" folder\n",
    "os.chdir(subfolder_with_path[0])\n",
    "\n",
    "#Counting number of files on \"ABAcluster_cropped\" folder to obtain number of clusters \n",
    "# and counting the number of columns in each file to count the number of samples\n",
    "# The clusters vector contains all clusters names\n",
    "#The samples_and_clusters matrix contains all samples names ordered in agreement witht the clusters vector\n",
    "\n",
    "clusters = os.listdir(subfolder_with_path[0]) \n",
    "number_of_clusters = len(clusters)\n",
    "samples_and_clusters_matrix = [\"\" for x in range(number_of_clusters)]\n",
    "\n",
    "i = 0\n",
    "while i < number_of_clusters:\n",
    "    samples = pd.read_csv(clusters[i],low_memory=False).columns.tolist()\n",
    "    samples_and_clusters_matrix[i] = samples\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2177dc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sample22',\n",
       "  'sample24',\n",
       "  'sample26',\n",
       "  'sample28',\n",
       "  'sample30',\n",
       "  'sample32',\n",
       "  'sample34',\n",
       "  'sample36',\n",
       "  'sample40',\n",
       "  'sample44',\n",
       "  'sample46',\n",
       "  'sample48',\n",
       "  'sample50',\n",
       "  'sample52',\n",
       "  'sample56',\n",
       "  'sample58',\n",
       "  'sample60',\n",
       "  'sample62',\n",
       "  'sample64',\n",
       "  'sample66',\n",
       "  'sample68',\n",
       "  'sample72',\n",
       "  'sample76',\n",
       "  'sample78',\n",
       "  'sample80',\n",
       "  'sample82',\n",
       "  'sample84',\n",
       "  'sample86',\n",
       "  'sample88',\n",
       "  'sample90',\n",
       "  'sample92',\n",
       "  'sample94',\n",
       "  'sample96'],\n",
       " ['sample22',\n",
       "  'sample24',\n",
       "  'sample26',\n",
       "  'sample28',\n",
       "  'sample30',\n",
       "  'sample32',\n",
       "  'sample34',\n",
       "  'sample36',\n",
       "  'sample40',\n",
       "  'sample44',\n",
       "  'sample46',\n",
       "  'sample48',\n",
       "  'sample50',\n",
       "  'sample52',\n",
       "  'sample56',\n",
       "  'sample58',\n",
       "  'sample60',\n",
       "  'sample62',\n",
       "  'sample64',\n",
       "  'sample66',\n",
       "  'sample68',\n",
       "  'sample72',\n",
       "  'sample76',\n",
       "  'sample78',\n",
       "  'sample80',\n",
       "  'sample82',\n",
       "  'sample84',\n",
       "  'sample86',\n",
       "  'sample88',\n",
       "  'sample90',\n",
       "  'sample92',\n",
       "  'sample94',\n",
       "  'sample96']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_and_clusters_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "992dfd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample22</th>\n",
       "      <th>sample24</th>\n",
       "      <th>sample26</th>\n",
       "      <th>sample28</th>\n",
       "      <th>sample30</th>\n",
       "      <th>sample32</th>\n",
       "      <th>sample34</th>\n",
       "      <th>sample36</th>\n",
       "      <th>sample40</th>\n",
       "      <th>sample44</th>\n",
       "      <th>...</th>\n",
       "      <th>sample78</th>\n",
       "      <th>sample80</th>\n",
       "      <th>sample82</th>\n",
       "      <th>sample84</th>\n",
       "      <th>sample86</th>\n",
       "      <th>sample88</th>\n",
       "      <th>sample90</th>\n",
       "      <th>sample92</th>\n",
       "      <th>sample94</th>\n",
       "      <th>sample96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>895553768.0</td>\n",
       "      <td>803963072.0</td>\n",
       "      <td>724225464.0</td>\n",
       "      <td>702383776.0</td>\n",
       "      <td>685517208.0</td>\n",
       "      <td>725218928.0</td>\n",
       "      <td>814788872.0</td>\n",
       "      <td>629501952.0</td>\n",
       "      <td>988086936.0</td>\n",
       "      <td>861131912.0</td>\n",
       "      <td>...</td>\n",
       "      <td>793103072.0</td>\n",
       "      <td>697965184.0</td>\n",
       "      <td>1011692800.0</td>\n",
       "      <td>753480648.0</td>\n",
       "      <td>855206496.0</td>\n",
       "      <td>1004899544.0</td>\n",
       "      <td>688276704.0</td>\n",
       "      <td>690876856.0</td>\n",
       "      <td>709564256.0</td>\n",
       "      <td>778507272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65531</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65532</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65533</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65534</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65535</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65536 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sample22     sample24     sample26     sample28     sample30  \\\n",
       "0      895553768.0  803963072.0  724225464.0  702383776.0  685517208.0   \n",
       "1              0.0          0.0          0.0          0.0          0.0   \n",
       "2              0.0          0.0          0.0          0.0          0.0   \n",
       "3              0.0          0.0          0.0          0.0          0.0   \n",
       "4              0.0          0.0          0.0          0.0          0.0   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "65531          0.0    0.000000     0.000000     0.000000     0.000000    \n",
       "65532          0.0    0.000000     0.000000     0.000000     0.000000    \n",
       "65533          0.0    0.000000     0.000000     0.000000     0.000000    \n",
       "65534          0.0    0.000000     0.000000     0.000000     0.000000    \n",
       "65535          NaN                                                       \n",
       "\n",
       "          sample32     sample34     sample36     sample40     sample44  ...  \\\n",
       "0      725218928.0  814788872.0  629501952.0  988086936.0  861131912.0  ...   \n",
       "1              0.0          0.0          0.0          0.0          0.0  ...   \n",
       "2              0.0          0.0          0.0          0.0          0.0  ...   \n",
       "3              0.0          0.0          0.0          0.0          0.0  ...   \n",
       "4              0.0          0.0          0.0          0.0          0.0  ...   \n",
       "...            ...          ...          ...          ...          ...  ...   \n",
       "65531    0.000000     0.000000     0.000000     0.000000     0.000000   ...   \n",
       "65532    0.000000     0.000000     0.000000     0.000000     0.000000   ...   \n",
       "65533    0.000000     0.000000     0.000000     0.000000     0.000000   ...   \n",
       "65534    0.000000     0.000000     0.000000     0.000000     0.000000   ...   \n",
       "65535                                                                   ...   \n",
       "\n",
       "          sample78     sample80      sample82     sample84     sample86  \\\n",
       "0      793103072.0  697965184.0  1011692800.0  753480648.0  855206496.0   \n",
       "1              0.0          0.0           0.0          0.0          0.0   \n",
       "2              0.0          0.0           0.0          0.0          0.0   \n",
       "3              0.0          0.0           0.0          0.0          0.0   \n",
       "4              0.0          0.0           0.0          0.0          0.0   \n",
       "...            ...          ...           ...          ...          ...   \n",
       "65531    0.000000     0.000000      0.000000     0.000000     0.000000    \n",
       "65532    0.000000     0.000000      0.000000     0.000000     0.000000    \n",
       "65533    0.000000     0.000000      0.000000     0.000000     0.000000    \n",
       "65534    0.000000     0.000000      0.000000     0.000000     0.000000    \n",
       "65535                                                                     \n",
       "\n",
       "           sample88     sample90     sample92     sample94     sample96  \n",
       "0      1004899544.0  688276704.0  690876856.0  709564256.0  778507272.0  \n",
       "1               0.0          0.0          0.0          0.0          0.0  \n",
       "2               0.0          0.0          0.0          0.0          0.0  \n",
       "3               0.0          0.0          0.0          0.0          0.0  \n",
       "4               0.0          0.0          0.0          0.0          0.0  \n",
       "...             ...          ...          ...          ...          ...  \n",
       "65531     0.000000     0.000000     0.000000     0.000000           0.0  \n",
       "65532     0.000000     0.000000     0.000000     0.000000           0.0  \n",
       "65533     0.000000     0.000000     0.000000     0.000000           0.0  \n",
       "65534     0.000000     0.000000     0.000000     0.000000           0.0  \n",
       "65535                                                               NaN  \n",
       "\n",
       "[65536 rows x 33 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = pd.read_csv(\"cluster_1_ABA_histogram.csv\")\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52545819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a loop to process all files and populate the main data-frame\n",
    "\n",
    "volume_data = [] #This array will contain df as elements\n",
    "\n",
    "i = 0\n",
    "while i < number_of_clusters:\n",
    "\n",
    "    ##############################################\n",
    "    # Processing each file\n",
    "    ##############################################\n",
    "    \n",
    "    file = clusters[i]\n",
    "    # Saving cluster's number\n",
    "    filename_segmented = file.split('_')\n",
    "    cluster_number = filename_segmented[1]\n",
    "\n",
    "    # Reading file's data\n",
    "    \n",
    "    header = [\"PIXEL_COUNT\"]\n",
    "    pixels_count_volume = pd.read_csv(file, names = header)\n",
    "    pixels_count_volume.insert(0, column = 'INTENSITY', value = range(0, len(pixels_count_volume))) \n",
    "\n",
    "    # Adding activity columns to intensitites template data-frame\n",
    "    output = gubra_intensities_template.merge(pixels_count_volume, how='left', left_on='LabelID', right_on='INTENSITY')\n",
    "    output = output.drop(columns=['INTENSITY'])\n",
    "    volume_label_name = 'VOLUME'\n",
    "    output = output.rename(columns = {'PIXEL_COUNT':volume_label_name})\n",
    "    output['VOLUME'] = output['VOLUME'].div(1000000).round(7)\n",
    "    \n",
    "    # Checking to which hemisphere the sample belongs to and erasing activity that belong to the other hemisphere\n",
    "    hemisphere = samples_overview['hemisphere'].loc[samples_overview['SAMPLE'] == int(sample)]\n",
    "    hemisphere = hemisphere.array\n",
    "    if hemisphere[0] == 'left':\n",
    "        output = output[output['LabelID'] > 20000]\n",
    "    else:\n",
    "        output = output[output['LabelID'] < 20000]\n",
    "   \n",
    "\n",
    "    # Adding a column of the sample number\n",
    "    sample_column = np.empty(len(output))\n",
    "    sample = int(sample)\n",
    "    sample_column.fill(sample)\n",
    "    output['SAMPLE'] = sample_column\n",
    "    \n",
    "    # Erasing the hemisphere label form the \"raw\" and the and \"labelabrv\" columns\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('left_','')\n",
    "    output[\"raw\"] = output[\"raw\"].str.replace('right_','')\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('L','',1)\n",
    "    output[\"LabelAbrv\"] = output[\"LabelAbrv\"].str.replace('R','',1)\n",
    "    \n",
    "    ##########################################################################################################################\n",
    "    \n",
    "    # store DataFrame in list\n",
    "    volume_data.append(output)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#Joinning all elements of the array in a dataframe\n",
    "volume_data = pd.concat(volume_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7492fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['a','b','c','d','e']\n",
    "string =['PIXEL_COUNT_']\n",
    "df = pd.DataFrame('x', index=range(3), columns=['a','b','c','d','e'])\n",
    "df = df.add_suffix('_PIXEL_COUNT')\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
